{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Author - Danish Gufran\n",
        "# Danish.Gufran@colostate.edu\n",
        "\n",
        "# Citation : https://ieeexplore.ieee.org/document/10323477\n",
        "\n",
        "'''\n",
        "STELLAR: Siamese Multi-Headed Attention Neural Networks for Overcoming\n",
        "Temporal Variations and Device Heterogeneity\n",
        "With Indoor Localization\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Urn8piKzSqxQ",
        "outputId": "4dd74637-820a-44ec-9a96-0a672c5f9477"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSTELLAR: Siamese Multi-Headed Attention Neural Networks for Overcoming \\nTemporal Variations and Device Heterogeneity \\nWith Indoor Localization\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT8GeBUZ_f9E",
        "outputId": "d5a4b777-4d54-496a-b8b9-a707920d3dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RSS_Database'...\n",
            "remote: Enumerating objects: 1521, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1521 (delta 0), reused 5 (delta 0), pack-reused 1516\u001b[K\n",
            "Receiving objects: 100% (1521/1521), 182.30 MiB | 15.51 MiB/s, done.\n",
            "Resolving deltas: 100% (738/738), done.\n",
            "Updating files: 100% (1655/1655), done.\n",
            "Cloning into 'EPIC_Lab_Data'...\n",
            "remote: Enumerating objects: 328, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 328 (delta 79), reused 105 (delta 77), pack-reused 221\u001b[K\n",
            "Receiving objects: 100% (328/328), 86.35 MiB | 15.90 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "Updating files: 100% (338/338), done.\n",
            "Cloning into 'heterogeneous-rssi-indoor-nav'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 80 (delta 1), reused 0 (delta 0), pack-reused 74\u001b[K\n",
            "Receiving objects: 100% (80/80), 4.07 MiB | 7.50 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.3/612.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.22.0 typeguard-2.13.3\n",
            "Collecting keras-multi-head\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention==0.51.0->keras-multi-head) (1.23.5)\n",
            "Building wheels for collected packages: keras-multi-head, keras-self-attention\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14976 sha256=78f75195db26022642266800e8d608007b50dfddb4e7bb5a6ba9ffb991fc0b18\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=bb23f4c7d7dd4b30b4f75def153c6d813a07dfb4e1acf683121c756d9902a219\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "Successfully built keras-multi-head keras-self-attention\n",
            "Installing collected packages: keras-self-attention, keras-multi-head\n",
            "Successfully installed keras-multi-head-0.29.0 keras-self-attention-0.51.0\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ],
      "source": [
        "# !rm -rf maril\n",
        "!git clone https://github.com/danishgufran/RSS_Database.git\n",
        "!git clone https://github.com/danishgufran/EPIC_Lab_Data.git\n",
        "!git clone https://github.com/EPIC-CSU/heterogeneous-rssi-indoor-nav.git\n",
        "!pip install tensorflow-addons\n",
        "!pip install keras-multi-head\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D , LSTM, Attention\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.optimizers import*\n",
        "import random as random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import pandas as pd\n",
        "\n",
        "import RSS_Database.Stone_Seth.Seth\n",
        "from RSS_Database.Stone_Seth.Seth import fetch_seth, Devices, Floorplan, get_mac_ids\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from EPIC_Lab_Data.data import Devices, Floorplan, build_dataset\n",
        "from EPIC_Lab_Data.helpers import compute_distances\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "import logging\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LayerNormalization\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import Loss\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import svm\n",
        "import xgboost as xgb\n",
        "\n",
        "from EPIC_Lab_Data.helpers import split_frame, compute_distances\n",
        "from EPIC_Lab_Data.data import build_dataset\n",
        "from EPIC_Lab_Data.Maril.MultiHeadAttentionAddon import MultiHeadAttentionAddon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixhfUhNmSynl",
        "outputId": "5405bab2-6d35-42cb-ca43-02891f3f5a62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_data(itr,dev, floorplan):\n",
        "    # dfs is a list of dataframes\n",
        "# meta is a dataframe with meta data\n",
        "\n",
        "#getting train data\n",
        "\n",
        "    train_fp, train_meta = fetch_seth(\n",
        "    dev,\n",
        "    str(floorplan),\n",
        "    ci = int(itr),\n",
        "    base_path=\"RSS_Database/Stone_Seth/temp/clean/\"  # <-- this would be 'seth/temp/clean' from outside this dir\n",
        ")\n",
        "    # train_fp, _, macs, lbl2cord = build_dataset(\n",
        "    #     dev,\n",
        "    #     str(floorplan),\n",
        "    # )\n",
        "    train_fp = train_fp.sample(frac=1).reset_index(drop=True)\n",
        "    train_aps = get_mac_ids(train_fp.columns)\n",
        "    train_x = train_fp[train_aps].values\n",
        "    # train_x = (train_x + 100)/100\n",
        "    train_y = (train_fp[\"label\"]).values\n",
        "    return train_x, train_y, train_aps\n",
        "\n",
        "def test_data(itr, train_aps, dev, floorplan):\n",
        "    #getting test data\n",
        "    test_fp, test_meta = fetch_seth(\n",
        "    dev ,\n",
        "    str(floorplan),\n",
        "    ci = itr,\n",
        "    base_path=\"RSS_Database/Stone_Seth/temp/clean/\"  # <-- this would be 'seth/temp/clean' from outside this dir\n",
        ")\n",
        "    # train_df, test_fp, macs_test, lbl2cords = build_dataset(\n",
        "    #       dev,\n",
        "    #       str(floorplan)\n",
        "    #   )\n",
        "    test_y = test_fp[\"label\"].values\n",
        "    # train_aps = train_aps.drop(['x', 'y','label'], axis=1)\n",
        "    # print(f'label -- {test_y}')\n",
        "    test_aps = get_mac_ids(test_fp.columns)\n",
        "    missing_aps = list(set(train_aps.columns)-set(test_aps))\n",
        "    test_fp[missing_aps] = 0\n",
        "\n",
        "    test_fp = test_fp.drop(['x', 'y','label'], axis=1)\n",
        "    test_x = test_fp[:]\n",
        "\n",
        "    # test_x = (test_x + 100)/100\n",
        "\n",
        "\n",
        "    return test_x, test_y\n",
        "\n",
        "def temp_train_data(dev, floorplan, ci_val):\n",
        "    # dfs is a list of dataframes\n",
        "# meta is a dataframe with meta data\n",
        "\n",
        "#getting train data\n",
        "\n",
        "    train_fp, train_meta = fetch_seth(\n",
        "    dev,\n",
        "    str(floorplan),\n",
        "    ci = ci_val,\n",
        "    base_path=\"RSS_Database/Stone_Seth/temp/clean/\"  # <-- this would be 'seth/temp/clean' from outside this dir\n",
        ")\n",
        "    # train_fp, _, macs, lbl2cord = build_dataset(\n",
        "    #     dev,\n",
        "    #     str(floorplan),\n",
        "    # )\n",
        "    train_fp = train_fp.sample(frac=1).reset_index(drop=True)\n",
        "    train_aps = get_mac_ids(train_fp.columns)\n",
        "    train_x = train_fp[train_aps].values\n",
        "    train_x = (train_x + 100)/100\n",
        "    train_y = (train_fp[\"label\"]).values\n",
        "    return train_x, train_y, train_aps\n",
        "def temp_test_data(train_aps, dev, floorplan, ci_val):\n",
        "    #getting test data\n",
        "    test_fp, test_meta = fetch_seth(\n",
        "    str(dev) ,\n",
        "    str(floorplan),\n",
        "    ci = ci_val,\n",
        "    base_path=\"RSS_Database/Stone_Seth/temp/clean/\"  # <-- this would be 'seth/temp/clean' from outside this dir\n",
        ")\n",
        "    # train_df, test_fp, macs_test, lbl2cords = build_dataset(\n",
        "    #       dev,\n",
        "    #       str(floorplan)\n",
        "    #   )\n",
        "    test_aps = get_mac_ids(test_fp.columns)\n",
        "    missing_aps = list(set(train_aps)-set(test_aps))\n",
        "    test_fp[missing_aps] = 0\n",
        "    test_x = test_fp[train_aps].values\n",
        "    test_x = (test_x + 100)/100\n",
        "    test_y = (test_fp[\"label\"]).values\n",
        "    return test_x, test_y"
      ],
      "metadata": {
        "id": "fZCKI2YL_5Pk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Anvil:\n",
        "    \"\"\"\n",
        "    Manage and build model\n",
        "    NOTE: Lacks configurability; Needs fixing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_device,\n",
        "        floorplan,\n",
        "        num_heads=7,\n",
        "        head_size=50,\n",
        "        data_path=\"EPIC_Lab_Data/Data\",\n",
        "        model_path=\"EPIC_Lab_Data/Maril/saved_models\",\n",
        "        model_name=None,\n",
        "    ):\n",
        "        self.device = train_device\n",
        "        self.floorplan = floorplan\n",
        "        self.data_path = data_path\n",
        "        self.model_path = model_path\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = head_size\n",
        "        self.final = []\n",
        "\n",
        "\n",
        "        self.model = None\n",
        "\n",
        "        _, _, self.macs, _ = build_dataset(\n",
        "            self.device,\n",
        "            self.floorplan,\n",
        "            base_path=self.data_path,\n",
        "        )\n",
        "\n",
        "        # build meta\n",
        "        self.meta = {\n",
        "            \"NUM_HEADS\": num_heads,\n",
        "            \"HEAD_SIZE\": head_size,\n",
        "            \"MACS\": list(self.macs),\n",
        "            \"TRAIN_DEVICE\": self.device,\n",
        "            \"TRAIN_FLOORPLAN\": self.floorplan,\n",
        "        }\n",
        "\n",
        "        if model_name is None:\n",
        "            self.model_name = f\"DA_{train_device}_{floorplan}\"\n",
        "        else:\n",
        "            self.model_name = model_name\n",
        "\n",
        "    def build(self):\n",
        "\n",
        "        train_df, _, macs, lbl2cords = build_dataset(\n",
        "            self.device,\n",
        "            self.floorplan,\n",
        "            base_path=self.data_path,\n",
        "        )\n",
        "\n",
        "        td = self.device\n",
        "        train_df_rst, _, train_macs_rst, lbl2cord_rst = build_dataset(\n",
        "          td,\n",
        "          self.floorplan,\n",
        "      )\n",
        "        missing_waps_rst = list(set(macs) - set(train_macs_rst))\n",
        "        _df = train_df_rst.copy()  # supresses fragmented df warning\n",
        "        _df[missing_waps_rst] = 0.0\n",
        "        keys = _df[train_macs_rst].values.astype(float)\n",
        "        values = keras.utils.to_categorical(_df[\"label\"].values.astype(int))\n",
        "\n",
        "        if self.floorplan == 'engr0':\n",
        "          shp = len(set(train_macs_rst)) + 1\n",
        "\n",
        "        if self.floorplan == 'engr1':\n",
        "          shp = len(set(train_macs_rst))\n",
        "\n",
        "        input_shape = shp\n",
        "        output_shape = len(lbl2cords.keys())\n",
        "        # keys = train_df[macs].values.astype(float)\n",
        "        # values = keras.utils.to_categorical(train_df[\"label\"].values.astype(int))\n",
        "\n",
        "        # input\n",
        "        input_layer = tf.keras.Input(shape=input_shape, name=\"query\")\n",
        "        x = input_layer\n",
        "        print(input_shape)\n",
        "\n",
        "        # augmentation # FASt Layer?\n",
        "        if \"NODA\" in self.model_name:\n",
        "            pass\n",
        "        else:\n",
        "            x = keras.layers.Normalization()(x)\n",
        "            x = keras.layers.Dropout(0.1)(x)\n",
        "\n",
        "\n",
        "            # x = MaskedDropout(0.10)(x)\n",
        "            # x = MaskedRandomBrightness(0.10, is_img=False)(x)\n",
        "            # x = MaskedRandomContrast(0.10, is_img=False)(x)\n",
        "\n",
        "        # noise\n",
        "        x = keras.layers.GaussianNoise(0.12)(x)\n",
        "\n",
        "        # MultiHeadLayer\n",
        "        x = MultiHeadAttentionAddon(\n",
        "            head_size=self.head_size,\n",
        "            num_heads=self.num_heads,\n",
        "            # output_size=None,\n",
        "            name=\"MHA\",\n",
        "            dropout=0.10,\n",
        "        )([x, keys, values])\n",
        "\n",
        "        # DNN layers\n",
        "        x = keras.layers.Dense(50, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(0.10)(x)\n",
        "        x = keras.layers.Dense(100, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(0.10)(x)\n",
        "\n",
        "        # output layer\n",
        "        output_layer = keras.layers.Dense(output_shape, activation=\"softmax\")(x)\n",
        "\n",
        "        # Connect the input and output model\n",
        "        self.model = tf.keras.Model(\n",
        "            inputs=input_layer, outputs=output_layer, name=self.model_name\n",
        "        )\n",
        "        return self.model\n",
        "\n",
        "    def create_siamese_network(self, input_shape, num_heads, key_dim, dff, embedding_dim):\n",
        "        output_classes = 61\n",
        "\n",
        "        input_anchor = Input(shape=input_shape, name='anchor_input')\n",
        "        input_positive = Input(shape=input_shape, name='positive_input')\n",
        "        input_negative = Input(shape=input_shape, name='negative_input')\n",
        "\n",
        "        shared_embedding = Dense(dff)\n",
        "\n",
        "        multihead_attention = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
        "        attention_layer_norm = LayerNormalization()\n",
        "        flatten = Flatten()\n",
        "\n",
        "        embedded_anchor = shared_embedding(input_anchor)\n",
        "        embedded_positive = shared_embedding(input_positive)\n",
        "        embedded_negative = shared_embedding(input_negative)\n",
        "\n",
        "        # One-hot encode train_y\n",
        "        train_y_input_tensor = Input(shape=(output_classes,), name='train_y_input')\n",
        "\n",
        "        attention_anchor = self.model(input_anchor)\n",
        "        attention_positive = self.model(input_positive)\n",
        "        attention_negative = self.model(input_negative)\n",
        "\n",
        "        attention_anchor = attention_layer_norm(attention_anchor)\n",
        "        attention_positive = attention_layer_norm(attention_positive)\n",
        "        attention_negative = attention_layer_norm(attention_negative)\n",
        "\n",
        "        embedded_anchor = Dense(embedding_dim, activation='relu')(flatten(attention_anchor))\n",
        "        embedded_positive = Dense(embedding_dim, activation='relu')(flatten(attention_positive))\n",
        "        embedded_negative = Dense(embedding_dim, activation='relu')(flatten(attention_negative))\n",
        "\n",
        "        # Use shape of train_y in Softmax layer\n",
        "        softmax_output = Dense(output_classes, activation='softmax', name='softmax_output')(embedded_anchor)\n",
        "\n",
        "        siamese_model = Model(\n",
        "            inputs=[input_anchor, input_positive, input_negative, train_y_input_tensor],\n",
        "            outputs=[embedded_anchor, embedded_positive, embedded_negative, softmax_output]\n",
        "        )\n",
        "        return siamese_model\n",
        "\n",
        "# This is just to test\n",
        "def shuffle_arrays(data_array):\n",
        "    np.random.shuffle(data_array)\n",
        "    return data_array\n",
        "\n",
        "# This is just to test\n",
        "def reverse_arrays(data_array):\n",
        "    reversed_data_array = np.flip(data_array, axis=0)\n",
        "    return reversed_data_array\n",
        "\n",
        "\n",
        "def replace_with_zeros(array, replace_percent):\n",
        "    num_samples = array.shape[0]\n",
        "    num_features = array.shape[1]\n",
        "    num_replacements = int(num_samples * num_features * replace_percent)\n",
        "\n",
        "    # Flatten the array\n",
        "    flattened_array = array.flatten()\n",
        "\n",
        "    # Get random indices for replacements\n",
        "    replace_indices = np.random.choice(num_samples * num_features, num_replacements, replace=True)\n",
        "\n",
        "    # Replace selected indices with zeros\n",
        "    flattened_array[replace_indices] = 0\n",
        "\n",
        "    # Reshape back to original shape\n",
        "    modified_array = flattened_array.reshape((num_samples, num_features))\n",
        "\n",
        "    return modified_array\n",
        "\n",
        "class TripletLoss(Loss):\n",
        "    def call(self, y_true, y_pred):\n",
        "        anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
        "        distance_positive = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "        distance_negative = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
        "        return tf.maximum(distance_positive - distance_negative + 0.2, 0.0)\n",
        "        # return tf.maximum(distance_positive - distance_negative , 0.0)\n"
      ],
      "metadata": {
        "id": "y4JeoWHnJ-Jp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions Below :\n",
        "\n",
        "train_dev = ['OP3']\n",
        "\n",
        "dev = ['BLU','HTC','LG','MOTO','OP3','S7']\n",
        "\n",
        "floorplan = ['engr0', 'engr1']\n",
        "\n",
        "# Drop D% of APs Randomly\n",
        "D_percent_drop = 0.60\n",
        "\n",
        "# CI Start to test\n",
        "ci_initial = 0\n",
        "\n",
        "# CI Max to test\n",
        "ci_max = 10\n",
        "\n",
        "# Hyper-Parameter(s)\n",
        "num_heads = 5\n",
        "key_dim = 64\n",
        "dff = 128\n",
        "embedding_dim = 64\n",
        "batchsize = 32\n",
        "epoch = 100\n",
        "\n",
        "for train in train_dev:\n",
        "    for flp in floorplan:\n",
        "        print(f'\\n Train dev -> {train}   flp -> {flp} \\n')\n",
        "        # Initial CI only !!!\n",
        "        ci_val = 0\n",
        "        train_x, train_y, train_aps = temp_train_data(train, flp, ci_val)\n",
        "\n",
        "        # Example usage\n",
        "        input_shape = train_x.shape[1:]  # Exclude batch size\n",
        "        output_classes = train_y.shape[-1]  # Number of output classes\n",
        "\n",
        "        anvil_instance = Anvil(train, flp)\n",
        "        model = anvil_instance.build()  # Build the Anvil model\n",
        "        siamese_model = anvil_instance.create_siamese_network(\n",
        "            input_shape=input_shape,\n",
        "            num_heads=num_heads,\n",
        "            key_dim=key_dim,\n",
        "            dff=dff,\n",
        "            embedding_dim=embedding_dim\n",
        "        )\n",
        "        siamese_model.summary()\n",
        "\n",
        "        # Compile the model with triplet loss\n",
        "        siamese_model.compile(optimizer=Adam(learning_rate=0.00001), loss=TripletLoss())\n",
        "\n",
        "        train_x_modified = replace_with_zeros(train_x, D_percent_drop)\n",
        "\n",
        "        # Example usage\n",
        "        # shuffled_train_x = shuffle_arrays(train_x)\n",
        "        shuffled_train_x = reverse_arrays(train_x)\n",
        "\n",
        "        print(f\"\\n Training the Siamese Multi-Headed Attention Neural Network (Encoder) - Train : {train} - Floorplan : {flp}\\n\")\n",
        "        print(\"... \\n\")\n",
        "        # Train the model with your data\n",
        "        siamese_model.fit(\n",
        "            x=[train_x, train_x_modified, shuffled_train_x, train_y],\n",
        "            y=[train_y, train_y, train_y, train_y],\n",
        "            batch_size=batchsize,\n",
        "            epochs=epoch,\n",
        "            verbose = 0\n",
        "        )\n",
        "\n",
        "        print(\"Encoding (STELLAR) Complete\")\n",
        "        print(\"\\n Post Encoding Non-Parametric Model(s) ... \\n\")\n",
        "        # Extract the encoded output for training data\n",
        "        anchor_siamese_model = Model(siamese_model.input[0], siamese_model.output[-1])\n",
        "        encoded_train_output = anchor_siamese_model.predict(train_x)\n",
        "        # encoded_train_output_reshaped = []\n",
        "\n",
        "        # Create and fit the KNN classifier\n",
        "        knn_classifier = KNeighborsClassifier(n_neighbors=20)\n",
        "        print('Training the KNN classifier')\n",
        "        knn_classifier.fit(encoded_train_output, train_y)\n",
        "        print(\"Training Complete\")\n",
        "\n",
        "        # Create and fit the Random Forest classifier\n",
        "        random_forest_classifier = RandomForestClassifier(n_estimators=20)\n",
        "        print('Training the RF classifier')\n",
        "        random_forest_classifier.fit(encoded_train_output, train_y)\n",
        "        print(\"Training Complete\")\n",
        "\n",
        "        # Create and fit the SVM classifier\n",
        "        svm_classifier = svm.SVC(kernel='rbf')\n",
        "        print('Training the SVM classifier')\n",
        "        svm_classifier.fit(encoded_train_output, train_y)\n",
        "        print(\"Training Complete\")\n",
        "\n",
        "        # Set the parameters for XGBoost\n",
        "        params = {\n",
        "            'objective': 'multi:softmax',\n",
        "            'num_class': len(np.unique(train_y)),\n",
        "            'max_depth': 2,\n",
        "            'eta': 0.1,\n",
        "            'subsample': 0.5,\n",
        "            'colsample_bytree': 0.5\n",
        "        }\n",
        "\n",
        "\n",
        "        # Create the XGBoost classifier\n",
        "        print('Training the XgBoost classifier')\n",
        "        xgb_classifier = xgb.XGBClassifier(**params)\n",
        "        print(\"Training Complete\")\n",
        "\n",
        "        # Train the XGBoost classifier\n",
        "        xgb_classifier.fit(encoded_train_output, train_y)\n",
        "\n",
        "        from catboost import CatBoostClassifier\n",
        "        # Set the parameters for CatBoost\n",
        "        params = {\n",
        "            'iterations': 35,\n",
        "            'learning_rate': 0.1,\n",
        "            'depth': 6,\n",
        "            'loss_function': 'MultiClass',\n",
        "            'custom_metric': 'Accuracy',\n",
        "            'random_seed': 42\n",
        "        }\n",
        "\n",
        "        # Create the CatBoost classifier\n",
        "        print('Training the CatBoost classifier')\n",
        "        catboost_classifier = CatBoostClassifier(**params)\n",
        "\n",
        "        # Train the CatBoost classifier\n",
        "        catboost_classifier.fit(encoded_train_output, train_y, verbose = 0)\n",
        "        print(\"Training Complete\")\n",
        "\n",
        "\n",
        "        final_knn = []\n",
        "        final_rf = []\n",
        "        final_svm = []\n",
        "        final_xgb = []\n",
        "        final_ctb = []\n",
        "        final_ngb = []\n",
        "\n",
        "        for ci_val in range(int(ci_initial), int(ci_max)):\n",
        "          for test_dev in dev:\n",
        "\n",
        "              print(\"\\n Testing ... \\n\")\n",
        "              print(f'Test dev -> {test_dev}   flp -> {flp}  Ci -> {ci_val}')\n",
        "              test_x, test_y = temp_test_data(train_aps, test_dev, flp, ci_val)\n",
        "              prediction_model = Model(siamese_model.input[0], siamese_model.output[-1])\n",
        "\n",
        "              pred = prediction_model.predict(test_x)\n",
        "\n",
        "              predicted_labels_knn = knn_classifier.predict(pred)\n",
        "              predicted_labels_rf = random_forest_classifier.predict(pred)\n",
        "              predicted_labels_svm = svm_classifier.predict(pred)\n",
        "              predicted_labels_xgb = xgb_classifier.predict(pred)\n",
        "              predicted_labels_ctb = catboost_classifier.predict(pred)\n",
        "\n",
        "              mean_error_knn = np.mean(np.abs(predicted_labels_knn - test_y))\n",
        "              mean_error_rf = np.mean(np.abs(predicted_labels_rf - test_y))\n",
        "              mean_error_svm = np.mean(np.abs(predicted_labels_svm - test_y))\n",
        "              mean_error_xgb = np.mean(np.abs(predicted_labels_xgb - test_y))\n",
        "              mean_error_ctb = np.mean(np.abs(predicted_labels_ctb - test_y))\n",
        "\n",
        "              final_knn.append(mean_error_knn)\n",
        "              final_rf.append(mean_error_rf)\n",
        "              final_svm.append(mean_error_svm)\n",
        "              final_xgb.append(mean_error_xgb)\n",
        "              final_ctb.append(mean_error_ctb)\n",
        "\n",
        "              print(f'Mean Error -> KNN {mean_error_knn} -> RF {mean_error_rf} -> SVM {mean_error_svm} -> XgB  {mean_error_xgb} -> CtB {mean_error_ctb}')\n",
        "            # print(predicted_labels - test_y)\n",
        "          print(f'Final Mean Error for: {flp} \\n-> KNN {np.mean(final_knn)} \\n-> RF {np.mean(final_rf)} \\n-> SVM {np.mean(final_svm)} \\n-> XgB  {np.mean(final_xgb)} \\n-> CtB {np.mean(final_ctb)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6VgGIGYS7BG",
        "outputId": "1d2a8842-1008-4338-ac74-2da35dd3a60b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Train dev -> OP3   flp -> engr0 \n",
            "\n",
            "165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_57\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " anchor_input (InputLayer)   [(None, 165)]                0         []                            \n",
            "                                                                                                  \n",
            " DA_OP3_engr0 (Functional)   (None, 61)                   172603    ['anchor_input[0][0]',        \n",
            "                                                                     'positive_input[0][0]',      \n",
            "                                                                     'negative_input[0][0]']      \n",
            "                                                                                                  \n",
            " positive_input (InputLayer  [(None, 165)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " negative_input (InputLayer  [(None, 165)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 61)                   122       ['DA_OP3_engr0[0][0]',        \n",
            " erNormalization)                                                    'DA_OP3_engr0[1][0]',        \n",
            "                                                                     'DA_OP3_engr0[2][0]']        \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 61)                   0         ['layer_normalization_1[0][0]'\n",
            "                                                                    , 'layer_normalization_1[1][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'layer_normalization_1[2][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 64)                   3968      ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " train_y_input (InputLayer)  [(None, 61)]                 0         []                            \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 64)                   3968      ['flatten_1[1][0]']           \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 64)                   3968      ['flatten_1[2][0]']           \n",
            "                                                                                                  \n",
            " softmax_output (Dense)      (None, 61)                   3965      ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 188594 (736.70 KB)\n",
            "Trainable params: 188263 (735.40 KB)\n",
            "Non-trainable params: 331 (1.30 KB)\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            " Training the Siamese Multi-Headed Attention Neural Network (Encoder) - Train : OP3 - Floorplan : engr0\n",
            "\n",
            "... \n",
            "\n",
            "Encoding (STELLAR) Complete\n",
            "\n",
            " Post Encoding Non-Parametric Model(s) ... \n",
            "\n",
            "12/12 [==============================] - 0s 7ms/step\n",
            "Training the KNN classifier\n",
            "Training Complete\n",
            "Training the RF classifier\n",
            "Training Complete\n",
            "Training the SVM classifier\n",
            "Training Complete\n",
            "Training the XgBoost classifier\n",
            "Training Complete\n",
            "Training the CatBoost classifier\n",
            "Training Complete\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 0\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 10.639344262295081 -> RF 11.407103825136613 -> SVM 12.887978142076502 -> XgB  8.655737704918034 -> CtB 17.69842336289528\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 0\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 10.278688524590164 -> RF 10.05464480874317 -> SVM 12.319672131147541 -> XgB  7.2923497267759565 -> CtB 17.59746483920093\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 0\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 11.221311475409836 -> RF 12.224043715846994 -> SVM 13.046448087431694 -> XgB  9.980874316939891 -> CtB 16.81272955298755\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 0\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "Mean Error -> KNN 8.289617486338798 -> RF 9.66120218579235 -> SVM 8.78688524590164 -> XgB  7.48087431693989 -> CtB 20.31608886500045\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 0\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 4.314207650273224 -> RF 8.01639344262295 -> SVM 5.128415300546448 -> XgB  0.02185792349726776 -> CtB 20.44544477291051\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 0\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 7.904371584699454 -> RF 8.937158469945356 -> SVM 10.065573770491802 -> XgB  7.360655737704918 -> CtB 17.967750604676162\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 8.774590163934427 \n",
            "-> RF 10.050091074681239 \n",
            "-> SVM 10.372495446265939 \n",
            "-> XgB  6.798724954462659 \n",
            "-> CtB 18.47298366627848\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 1\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 10.792349726775956 -> RF 11.530054644808743 -> SVM 12.341530054644808 -> XgB  7.101092896174864 -> CtB 16.86365672310311\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 1\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "Mean Error -> KNN 9.912568306010929 -> RF 10.16120218579235 -> SVM 11.833333333333334 -> XgB  7.901639344262295 -> CtB 17.978948311385828\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 1\n",
            "12/12 [==============================] - 0s 7ms/step\n",
            "Mean Error -> KNN 11.398907103825136 -> RF 11.587431693989071 -> SVM 13.051912568306012 -> XgB  9.953551912568306 -> CtB 16.69699005643644\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 1\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 6.7349726775956285 -> RF 9.210382513661202 -> SVM 7.248633879781421 -> XgB  8.366120218579235 -> CtB 23.205634686016303\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 1\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 7.959016393442623 -> RF 9.243169398907105 -> SVM 7.273224043715847 -> XgB  6.729508196721311 -> CtB 25.10655737704918\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 1\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "Mean Error -> KNN 8.55464480874317 -> RF 8.857923497267759 -> SVM 10.521857923497267 -> XgB  7.475409836065574 -> CtB 18.51012272686554\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 9.000000000000002 \n",
            "-> RF 10.074225865209472 \n",
            "-> SVM 10.375455373406192 \n",
            "-> XgB  7.359972677595629 \n",
            "-> CtB 19.09998432321061\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 2\n",
            "12/12 [==============================] - 0s 7ms/step\n",
            "Mean Error -> KNN 11.081967213114755 -> RF 11.55464480874317 -> SVM 12.956284153005464 -> XgB  7.748633879781421 -> CtB 17.784735286213383\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 2\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 9.352459016393443 -> RF 9.174863387978142 -> SVM 11.229508196721312 -> XgB  7.1256830601092895 -> CtB 18.96345068529965\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 2\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "Mean Error -> KNN 10.658469945355192 -> RF 10.53551912568306 -> SVM 12.562841530054644 -> XgB  9.013661202185792 -> CtB 17.31295350712174\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 2\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 6.672131147540983 -> RF 8.59016393442623 -> SVM 7.251366120218579 -> XgB  5.877049180327869 -> CtB 19.975947325987637\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 2\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "Mean Error -> KNN 5.76775956284153 -> RF 8.37704918032787 -> SVM 6.133879781420765 -> XgB  8.087431693989071 -> CtB 19.063558183284062\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 2\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "Mean Error -> KNN 9.03551912568306 -> RF 9.202185792349727 -> SVM 10.811475409836065 -> XgB  7.243169398907104 -> CtB 17.925915972408852\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 8.920461445051608 \n",
            "-> RF 9.906952034001215 \n",
            "-> SVM 10.302823315118397 \n",
            "-> XgB  7.411961141469338 \n",
            "-> CtB 18.901465157713478\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 3\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 9.53825136612022 -> RF 10.084699453551913 -> SVM 11.614754098360656 -> XgB  6.48087431693989 -> CtB 17.494042820030458\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 3\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 9.898907103825136 -> RF 10.079234972677595 -> SVM 11.89344262295082 -> XgB  7.748633879781421 -> CtB 18.146600376242944\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 3\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 11.243169398907105 -> RF 11.898907103825136 -> SVM 13.07103825136612 -> XgB  10.939890710382514 -> CtB 17.216339693630744\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 3\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 6.806010928961749 -> RF 8.519125683060109 -> SVM 7.590163934426229 -> XgB  5.174863387978142 -> CtB 21.103153274209443\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 3\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 7.48087431693989 -> RF 9.262295081967213 -> SVM 7.69672131147541 -> XgB  5.825136612021858 -> CtB 21.074845471647407\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 3\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 8.959016393442623 -> RF 9.188524590163935 -> SVM 10.530054644808743 -> XgB  7.098360655737705 -> CtB 18.247514109110455\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 8.937272313296903 \n",
            "-> RF 9.889913479052824 \n",
            "-> SVM 10.32695810564663 \n",
            "-> XgB  7.3617941712204 \n",
            "-> CtB 18.896202857654753\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 4\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 9.426229508196721 -> RF 9.942622950819672 -> SVM 11.6775956284153 -> XgB  7.306010928961749 -> CtB 17.20406700707695\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 4\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 7.245901639344262 -> RF 7.726775956284153 -> SVM 9.653005464480874 -> XgB  6.860655737704918 -> CtB 18.1327600107498\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 4\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 11.26775956284153 -> RF 11.404371584699453 -> SVM 13.095628415300547 -> XgB  9.950819672131148 -> CtB 17.07009764400251\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 4\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "Mean Error -> KNN 7.251366120218579 -> RF 9.289617486338798 -> SVM 7.639344262295082 -> XgB  7.666666666666667 -> CtB 21.589939980292037\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 4\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 7.80327868852459 -> RF 8.28688524590164 -> SVM 8.210382513661202 -> XgB  6.9289617486338795 -> CtB 19.7352862133835\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 4\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 8.112021857923498 -> RF 8.09016393442623 -> SVM 9.491803278688524 -> XgB  5.4289617486338795 -> CtB 18.371226372838844\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 8.853369763205828 \n",
            "-> RF 9.736612021857924 \n",
            "-> SVM 10.253825136612022 \n",
            "-> XgB  7.360837887067394 \n",
            "-> CtB 18.853741527068586\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 5\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 11.084699453551913 -> RF 11.346994535519126 -> SVM 12.80327868852459 -> XgB  7.040983606557377 -> CtB 16.893711367911852\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 5\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 11.297814207650273 -> RF 11.524590163934427 -> SVM 12.693989071038251 -> XgB  10.437158469945356 -> CtB 16.886947953059213\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 5\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 12.002732240437158 -> RF 13.03551912568306 -> SVM 13.546448087431694 -> XgB  10.188524590163935 -> CtB 16.417450506136344\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 5\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 7.601092896174864 -> RF 10.16120218579235 -> SVM 8.05464480874317 -> XgB  8.472677595628415 -> CtB 18.921168144763953\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 5\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 7.060109289617486 -> RF 8.603825136612022 -> SVM 7.314207650273224 -> XgB  5.377049180327869 -> CtB 22.29727671772821\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 5\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 9.748633879781421 -> RF 9.745901639344263 -> SVM 11.581967213114755 -> XgB  8.344262295081966 -> CtB 17.058765564812326\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 9.011004857316331 \n",
            "-> RF 9.903233151183972 \n",
            "-> SVM 10.378035822707954 \n",
            "-> XgB  7.51904978749241 \n",
            "-> CtB 18.72465461295749\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 6\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 11.076502732240437 -> RF 11.887978142076502 -> SVM 12.759562841530055 -> XgB  8.967213114754099 -> CtB 16.359446385380274\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 6\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 10.153005464480874 -> RF 11.60655737704918 -> SVM 12.39344262295082 -> XgB  10.002732240437158 -> CtB 16.6689062080086\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 6\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "Mean Error -> KNN 12.133879781420765 -> RF 12.683060109289617 -> SVM 13.48360655737705 -> XgB  10.057377049180328 -> CtB 16.436800143330647\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 6\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 6.991803278688525 -> RF 9.073770491803279 -> SVM 7.508196721311475 -> XgB  8.226775956284152 -> CtB 19.384574039236764\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 6\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "Mean Error -> KNN 7.639344262295082 -> RF 9.420765027322405 -> SVM 8.136612021857923 -> XgB  5.5683060109289615 -> CtB 19.38202096210696\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 6\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 8.363387978142077 -> RF 9.308743169398907 -> SVM 10.3224043715847 -> XgB  7.680327868852459 -> CtB 17.272865717101137\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 9.065573770491804 \n",
            "-> RF 10.011839708561022 \n",
            "-> SVM 10.433645589383294 \n",
            "-> XgB  7.647345823575333 \n",
            "-> CtB 18.561718560038905\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 7\n",
            "12/12 [==============================] - 0s 12ms/step\n",
            "Mean Error -> KNN 10.912568306010929 -> RF 11.418032786885245 -> SVM 12.87431693989071 -> XgB  7.442622950819672 -> CtB 17.762608617755085\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 7\n",
            "12/12 [==============================] - 0s 11ms/step\n",
            "Mean Error -> KNN 10.751366120218579 -> RF 11.084699453551913 -> SVM 12.33879781420765 -> XgB  10.05464480874317 -> CtB 17.13571620532115\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 7\n",
            "12/12 [==============================] - 0s 11ms/step\n",
            "Mean Error -> KNN 12.128415300546449 -> RF 12.863387978142077 -> SVM 13.3551912568306 -> XgB  10.349726775956285 -> CtB 16.6829257368091\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 7\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 7.221311475409836 -> RF 7.576502732240437 -> SVM 7.669398907103825 -> XgB  4.844262295081967 -> CtB 21.288990414763056\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 7\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "Mean Error -> KNN 6.603825136612022 -> RF 8.721311475409836 -> SVM 5.797814207650274 -> XgB  6.663934426229508 -> CtB 19.427797187136076\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 7\n",
            "12/12 [==============================] - 0s 9ms/step\n",
            "Mean Error -> KNN 9.453551912568306 -> RF 9.489071038251366 -> SVM 11.021857923497267 -> XgB  8.166666666666666 -> CtB 17.506449879064768\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 9.121357012750456 \n",
            "-> RF 10.034380692167579 \n",
            "-> SVM 10.44313524590164 \n",
            "-> XgB  7.681466302367942 \n",
            "-> CtB 18.52909724088507\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 8\n",
            "12/12 [==============================] - 0s 7ms/step\n",
            "Mean Error -> KNN 11.584699453551913 -> RF 12.278688524590164 -> SVM 13.092896174863387 -> XgB  8.426229508196721 -> CtB 16.61390307265072\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 8\n",
            "12/12 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 9.78688524590164 -> RF 10.202185792349727 -> SVM 11.595628415300547 -> XgB  7.770491803278689 -> CtB 17.980739944459376\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 8\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 12.497267759562842 -> RF 13.021857923497267 -> SVM 13.628415300546449 -> XgB  10.415300546448087 -> CtB 16.524187046492877\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 8\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 8.923497267759563 -> RF 8.513661202185792 -> SVM 9.28688524590164 -> XgB  8.193989071038251 -> CtB 19.845919555674996\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 8\n",
            "12/12 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 6.691256830601093 -> RF 8.655737704918034 -> SVM 6.8469945355191255 -> XgB  6.418032786885246 -> CtB 19.416061990504346\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 8\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 9.592896174863387 -> RF 9.806010928961749 -> SVM 11.292349726775956 -> XgB  8.969945355191257 -> CtB 17.569918480695154\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 9.201882210078931 \n",
            "-> RF 10.076452135195304 \n",
            "-> SVM 10.500252985225663 \n",
            "-> XgB  7.757488362679619 \n",
            "-> CtB 18.469396252832606\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr0  Ci -> 9\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "Mean Error -> KNN 10.237704918032787 -> RF 10.415300546448087 -> SVM 11.90983606557377 -> XgB  6.918032786885246 -> CtB 16.997133387082325\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr0  Ci -> 9\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 10.032786885245901 -> RF 10.557377049180328 -> SVM 12.297814207650273 -> XgB  8.73224043715847 -> CtB 17.473394248857833\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr0  Ci -> 9\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 11.01639344262295 -> RF 11.704918032786885 -> SVM 13.030054644808743 -> XgB  10.030054644808743 -> CtB 17.188211054376065\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr0  Ci -> 9\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 6.743169398907104 -> RF 9.426229508196721 -> SVM 6.871584699453552 -> XgB  6.286885245901639 -> CtB 19.066559168682254\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr0  Ci -> 9\n",
            "12/12 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 6.23224043715847 -> RF 8.174863387978142 -> SVM 5.491803278688525 -> XgB  6.155737704918033 -> CtB 19.65551375078384\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr0  Ci -> 9\n",
            "12/12 [==============================] - 0s 6ms/step\n",
            "Mean Error -> KNN 7.871584699453552 -> RF 8.308743169398907 -> SVM 9.426229508196721 -> XgB  4.811475409836065 -> CtB 19.146197258801397\n",
            "Final Mean Error for: engr0 \n",
            "-> KNN 9.150591985428052 \n",
            "-> RF 10.04526411657559 \n",
            "-> SVM 10.434016393442624 \n",
            "-> XgB  7.697313296903461 \n",
            "-> CtB 18.447906775359073\n",
            "\n",
            " Train dev -> OP3   flp -> engr1 \n",
            "\n",
            "165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_119\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " anchor_input (InputLayer)   [(None, 165)]                0         []                            \n",
            "                                                                                                  \n",
            " DA_OP3_engr1 (Functional)   (None, 48)                   161877    ['anchor_input[0][0]',        \n",
            "                                                                     'positive_input[0][0]',      \n",
            "                                                                     'negative_input[0][0]']      \n",
            "                                                                                                  \n",
            " positive_input (InputLayer  [(None, 165)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " negative_input (InputLayer  [(None, 165)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 48)                   96        ['DA_OP3_engr1[0][0]',        \n",
            " erNormalization)                                                    'DA_OP3_engr1[1][0]',        \n",
            "                                                                     'DA_OP3_engr1[2][0]']        \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 48)                   0         ['layer_normalization_2[0][0]'\n",
            "                                                                    , 'layer_normalization_2[1][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'layer_normalization_2[2][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 64)                   3136      ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " train_y_input (InputLayer)  [(None, 61)]                 0         []                            \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 64)                   3136      ['flatten_2[1][0]']           \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 64)                   3136      ['flatten_2[2][0]']           \n",
            "                                                                                                  \n",
            " softmax_output (Dense)      (None, 61)                   3965      ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 175346 (684.95 KB)\n",
            "Trainable params: 175015 (683.65 KB)\n",
            "Non-trainable params: 331 (1.30 KB)\n",
            "__________________________________________________________________________________________________\n",
            "\n",
            " Training the Siamese Multi-Headed Attention Neural Network (Encoder) - Train : OP3 - Floorplan : engr1\n",
            "\n",
            "... \n",
            "\n",
            "Encoding (STELLAR) Complete\n",
            "\n",
            " Post Encoding Non-Parametric Model(s) ... \n",
            "\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Training the KNN classifier\n",
            "Training Complete\n",
            "Training the RF classifier\n",
            "Training Complete\n",
            "Training the SVM classifier\n",
            "Training Complete\n",
            "Training the XgBoost classifier\n",
            "Training Complete\n",
            "Training the CatBoost classifier\n",
            "Training Complete\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 0\n",
            "9/9 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 14.663194444444445 -> RF 12.041666666666666 -> SVM 13.90625 -> XgB  8.131944444444445 -> CtB 18.96383101851852\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 0\n",
            "9/9 [==============================] - 0s 7ms/step\n",
            "Mean Error -> KNN 11.006944444444445 -> RF 12.041666666666666 -> SVM 8.958333333333334 -> XgB  6.121527777777778 -> CtB 16.917824074074073\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 0\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 14.083333333333334 -> RF 12.041666666666666 -> SVM 13.847222222222221 -> XgB  6.722222222222222 -> CtB 17.453993055555557\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 0\n",
            "9/9 [==============================] - 0s 6ms/step\n",
            "Mean Error -> KNN 3.3541666666666665 -> RF 11.305555555555555 -> SVM 4.361111111111111 -> XgB  4.503472222222222 -> CtB 16.746961805555557\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 0\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 1.6875 -> RF 11.944444444444445 -> SVM 1.7986111111111112 -> XgB  0.0 -> CtB 15.923755787037036\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 0\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 4.041666666666667 -> RF 12.041666666666666 -> SVM 3.5729166666666665 -> XgB  5.690972222222222 -> CtB 17.15625\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 8.139467592592592 \n",
            "-> RF 11.902777777777779 \n",
            "-> SVM 7.740740740740741 \n",
            "-> XgB  5.195023148148148 \n",
            "-> CtB 17.19376929012346\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 1\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 14.71875 -> RF 12.041666666666666 -> SVM 13.743055555555555 -> XgB  6.100694444444445 -> CtB 19.04123263888889\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 1\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 7.993055555555555 -> RF 12.041666666666666 -> SVM 6.5625 -> XgB  5.888888888888889 -> CtB 16.40798611111111\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 1\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 13.95138888888889 -> RF 12.041666666666666 -> SVM 13.229166666666666 -> XgB  6.527777777777778 -> CtB 17.40205439814815\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 1\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 4.15625 -> RF 13.881944444444445 -> SVM 4.184027777777778 -> XgB  3.5416666666666665 -> CtB 15.808304398148149\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 1\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 4.986111111111111 -> RF 12.083333333333334 -> SVM 5.302083333333333 -> XgB  5.555555555555555 -> CtB 15.87717013888889\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 1\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 5.472222222222222 -> RF 12.041666666666666 -> SVM 5.024305555555555 -> XgB  5.659722222222222 -> CtB 16.99392361111111\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 8.342881944444445 \n",
            "-> RF 12.129050925925926 \n",
            "-> SVM 7.874131944444444 \n",
            "-> XgB  5.37037037037037 \n",
            "-> CtB 17.05777391975309\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 2\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 13.520833333333334 -> RF 12.041666666666666 -> SVM 13.600694444444445 -> XgB  8.375 -> CtB 18.90162037037037\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 2\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 13.09375 -> RF 12.041666666666666 -> SVM 10.711805555555555 -> XgB  5.822916666666667 -> CtB 16.46947337962963\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 2\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 11.086805555555555 -> RF 12.041666666666666 -> SVM 10.475694444444445 -> XgB  5.513888888888889 -> CtB 17.880787037037038\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 2\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 11.416666666666666 -> RF 12.041666666666666 -> SVM 11.225694444444445 -> XgB  5.791666666666667 -> CtB 17.912037037037038\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 2\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 3.4618055555555554 -> RF 12.11111111111111 -> SVM 4.142361111111111 -> XgB  3.6319444444444446 -> CtB 16.324363425925927\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 2\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 4.861111111111111 -> RF 11.98611111111111 -> SVM 4.340277777777778 -> XgB  5.131944444444445 -> CtB 17.97048611111111\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 8.753086419753085 \n",
            "-> RF 12.100694444444445 \n",
            "-> SVM 8.277006172839506 \n",
            "-> XgB  5.483989197530864 \n",
            "-> CtB 17.230669688786005\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 3\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 15.163194444444445 -> RF 12.041666666666666 -> SVM 15.395833333333334 -> XgB  7.604166666666667 -> CtB 18.564380787037038\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 3\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 12.45486111111111 -> RF 12.041666666666666 -> SVM 10.371527777777779 -> XgB  6.392361111111111 -> CtB 16.805555555555557\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 3\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 9.98611111111111 -> RF 12.041666666666666 -> SVM 9.097222222222221 -> XgB  6.017361111111111 -> CtB 16.47366898148148\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 3\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 5.482638888888889 -> RF 11.881944444444445 -> SVM 4.958333333333333 -> XgB  4.649305555555555 -> CtB 19.540653935185187\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 3\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 4.017361111111111 -> RF 16.0 -> SVM 3.763888888888889 -> XgB  3.923611111111111 -> CtB 16.080729166666668\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 3\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 4.739583333333333 -> RF 11.944444444444445 -> SVM 4.722222222222222 -> XgB  5.201388888888889 -> CtB 17.843605324074073\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 8.724971064814815 \n",
            "-> RF 12.240162037037038 \n",
            "-> SVM 8.220630787037036 \n",
            "-> XgB  5.520833333333333 \n",
            "-> CtB 17.310860339506174\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 4\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 10.76736111111111 -> RF 12.041666666666666 -> SVM 10.302083333333334 -> XgB  5.795138888888889 -> CtB 19.10127314814815\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 4\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 10.92013888888889 -> RF 12.041666666666666 -> SVM 8.961805555555555 -> XgB  5.680555555555555 -> CtB 16.61299189814815\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 4\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 13.805555555555555 -> RF 12.041666666666666 -> SVM 13.128472222222221 -> XgB  6.329861111111111 -> CtB 17.396556712962962\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 4\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 5.663194444444445 -> RF 12.041666666666666 -> SVM 5.246527777777778 -> XgB  4.923611111111111 -> CtB 17.607783564814813\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 4\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 4.079861111111111 -> RF 12.097222222222221 -> SVM 3.8472222222222223 -> XgB  4.201388888888889 -> CtB 16.109953703703702\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 4\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 4.194444444444445 -> RF 12.01388888888889 -> SVM 4.284722222222222 -> XgB  5.111111111111111 -> CtB 17.65277777777778\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 8.627662037037037 \n",
            "-> RF 12.201388888888893 \n",
            "-> SVM 8.102199074074074 \n",
            "-> XgB  5.484722222222222 \n",
            "-> CtB 17.33139949845679\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 5\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 14.774305555555555 -> RF 12.041666666666666 -> SVM 14.89236111111111 -> XgB  7.746527777777778 -> CtB 18.910734953703702\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 5\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 12.21875 -> RF 12.041666666666666 -> SVM 10.21875 -> XgB  5.482638888888889 -> CtB 17.12673611111111\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 5\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 16.229166666666668 -> RF 12.097222222222221 -> SVM 15.711805555555555 -> XgB  6.826388888888889 -> CtB 17.40523726851852\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 5\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 8.01736111111111 -> RF 12.041666666666666 -> SVM 6.96875 -> XgB  5.635416666666667 -> CtB 17.89308449074074\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 5\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 3.5659722222222223 -> RF 11.972222222222221 -> SVM 3.9652777777777777 -> XgB  4.034722222222222 -> CtB 16.11935763888889\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 5\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 4.684027777777778 -> RF 12.041666666666666 -> SVM 4.25 -> XgB  4.871527777777778 -> CtB 17.25245949074074\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 8.842206790123456 \n",
            "-> RF 12.174382716049385 \n",
            "-> SVM 8.307581018518515 \n",
            "-> XgB  5.531635802469136 \n",
            "-> CtB 17.351377636316872\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 6\n",
            "9/9 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 14.54513888888889 -> RF 12.041666666666666 -> SVM 14.003472222222221 -> XgB  7.954861111111111 -> CtB 19.33709490740741\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 6\n",
            "9/9 [==============================] - 0s 7ms/step\n",
            "Mean Error -> KNN 13.131944444444445 -> RF 12.041666666666666 -> SVM 12.40625 -> XgB  5.673611111111111 -> CtB 16.563802083333332\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 6\n",
            "9/9 [==============================] - 0s 9ms/step\n",
            "Mean Error -> KNN 13.875 -> RF 12.041666666666666 -> SVM 13.694444444444445 -> XgB  6.211805555555555 -> CtB 18.16333912037037\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 6\n",
            "9/9 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 3.642361111111111 -> RF 12.118055555555555 -> SVM 3.7118055555555554 -> XgB  3.9340277777777777 -> CtB 16.358796296296298\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 6\n",
            "9/9 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 5.861111111111111 -> RF 12.07638888888889 -> SVM 4.871527777777778 -> XgB  4.111111111111111 -> CtB 15.291377314814815\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 6\n",
            "9/9 [==============================] - 0s 8ms/step\n",
            "Mean Error -> KNN 5.194444444444445 -> RF 11.930555555555555 -> SVM 4.399305555555555 -> XgB  5.194444444444445 -> CtB 16.91015625\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 8.918320105820106 \n",
            "-> RF 12.15542328042328 \n",
            "-> SVM 8.384755291005291 \n",
            "-> XgB  5.529017857142858 \n",
            "-> CtB 17.31605144951499\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 7\n",
            "9/9 [==============================] - 0s 9ms/step\n",
            "Mean Error -> KNN 14.23611111111111 -> RF 12.041666666666666 -> SVM 14.39236111111111 -> XgB  7.548611111111111 -> CtB 19.072193287037038\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 7\n",
            "9/9 [==============================] - 0s 7ms/step\n",
            "Mean Error -> KNN 12.524305555555555 -> RF 12.041666666666666 -> SVM 9.9375 -> XgB  5.493055555555555 -> CtB 16.76953125\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 7\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 13.260416666666666 -> RF 12.041666666666666 -> SVM 12.770833333333334 -> XgB  5.131944444444445 -> CtB 17.29788773148148\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 7\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 2.5347222222222223 -> RF 11.743055555555555 -> SVM 2.611111111111111 -> XgB  4.125 -> CtB 15.715711805555555\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 7\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 11.461805555555555 -> RF 12.041666666666666 -> SVM 10.71875 -> XgB  5.677083333333333 -> CtB 16.438368055555557\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 7\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 8.809027777777779 -> RF 12.041666666666666 -> SVM 7.854166666666667 -> XgB  6.267361111111111 -> CtB 17.364872685185187\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 9.112413194444445 \n",
            "-> RF 12.134982638888888 \n",
            "-> SVM 8.550925925925926 \n",
            "-> XgB  5.5512876157407405 \n",
            "-> CtB 17.29026511863426\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 8\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 11.854166666666666 -> RF 12.041666666666666 -> SVM 11.788194444444445 -> XgB  6.277777777777778 -> CtB 19.595341435185187\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 8\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 11.46875 -> RF 12.041666666666666 -> SVM 9.8125 -> XgB  5.458333333333333 -> CtB 17.481336805555557\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 8\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 14.864583333333334 -> RF 12.041666666666666 -> SVM 14.902777777777779 -> XgB  6.680555555555555 -> CtB 16.96513310185185\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 8\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 6.260416666666667 -> RF 12.020833333333334 -> SVM 5.190972222222222 -> XgB  5.704861111111111 -> CtB 17.91304976851852\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 8\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 9.190972222222221 -> RF 12.041666666666666 -> SVM 7.048611111111111 -> XgB  6.020833333333333 -> CtB 17.12384259259259\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 8\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 5.197916666666667 -> RF 12.006944444444445 -> SVM 5.305555555555555 -> XgB  5.409722222222222 -> CtB 18.07711226851852\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 9.189493312757202 \n",
            "-> RF 12.1235853909465 \n",
            "-> SVM 8.601723251028806 \n",
            "-> XgB  5.592849794238681 \n",
            "-> CtB 17.353491512345677\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> BLU   flp -> engr1  Ci -> 9\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 16.760416666666668 -> RF 12.041666666666666 -> SVM 17.18402777777778 -> XgB  9.125 -> CtB 18.456452546296298\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> HTC   flp -> engr1  Ci -> 9\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 13.215277777777779 -> RF 12.041666666666666 -> SVM 11.67013888888889 -> XgB  6.166666666666667 -> CtB 16.85792824074074\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> LG   flp -> engr1  Ci -> 9\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 13.385416666666666 -> RF 12.041666666666666 -> SVM 12.319444444444445 -> XgB  5.642361111111111 -> CtB 16.40234375\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> MOTO   flp -> engr1  Ci -> 9\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 8.059027777777779 -> RF 13.159722222222221 -> SVM 8.79861111111111 -> XgB  6.909722222222222 -> CtB 15.516203703703704\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> OP3   flp -> engr1  Ci -> 9\n",
            "9/9 [==============================] - 0s 5ms/step\n",
            "Mean Error -> KNN 10.881944444444445 -> RF 12.041666666666666 -> SVM 8.975694444444445 -> XgB  5.958333333333333 -> CtB 15.698206018518519\n",
            "\n",
            " Testing ... \n",
            "\n",
            "Test dev -> S7   flp -> engr1  Ci -> 9\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "Mean Error -> KNN 3.75 -> RF 12.041666666666666 -> SVM 3.4444444444444446 -> XgB  5.197916666666667 -> CtB 16.824797453703702\n",
            "Final Mean Error for: engr1 \n",
            "-> KNN 9.371412037037038 \n",
            "-> RF 12.134027777777773 \n",
            "-> SVM 8.78142361111111 \n",
            "-> XgB  5.683564814814814 \n",
            "-> CtB 17.280741222993825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Author - Danish Gufran\n",
        "# Danish.Gufran@colostate.edu\n",
        "\n",
        "# Citation : https://ieeexplore.ieee.org/document/10323477\n",
        "\n",
        "'''\n",
        "STELLAR: Siamese Multi-Headed Attention Neural Networks for Overcoming\n",
        "Temporal Variations and Device Heterogeneity\n",
        "With Indoor Localization\n",
        "'''"
      ],
      "metadata": {
        "id": "8dHeQ1c2J3q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Final Mean Error for: {flp} \\n-> KNN {np.mean(final_knn)} \\n-> RF {np.mean(final_rf)} \\n-> SVM {np.mean(final_svm)} \\n-> XgB  {np.mean(final_xgb)} \\n-> CtB {np.mean(final_ctb)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pq0x6bZMJqk",
        "outputId": "2a052b0d-6f1e-47d7-af7f-fb6c20260913"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Mean Error for: engr1 \n",
            "-> KNN 5.462255658436213 \n",
            "-> RF 15.718235596707817 \n",
            "-> SVM 5.334812242798353 \n",
            "-> XgB  3.9659850823045266 \n",
            "-> CtB 16.625865376371742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3CobTrmMKCF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}